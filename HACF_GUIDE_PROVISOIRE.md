# üõ†Ô∏è Guide d'installation pour HACF (Provisoire)

Ce document t'explique √©tape par √©tape comment partager ton projet et comment l'installer proprement.

## 1. La Gen√®se (√Ä mettre dans ton post)
"√Ä force de jouer avec l'IA, je me retrouvais avec de nombreuses automatisations o√π je devais red√©finir √† chaque fois le prompt et le contexte. C'√©tait sympa au d√©but, mais c'est vite devenu une gal√®re √† maintenir. Comme j'adore les scripts, j'ai tout centralis√© pour simplifier mon code et gagner en robustesse."

## 2. Le Script YAML (Copier-Coller pour ton post)
Voici la version la plus claire possible, avec des commentaires expliquant chaque √©tape pour la communaut√©.

```yaml
# ID unique du script pour vos automatisations
k_2so_generateur_de_message:
  alias: K-2SO - G√©n√©rateur de Message
  description: 'G√©n√®re un message sarcastique style K-2SO via l''IA'
  
  # Configuration des entr√©es via l'UI de Home Assistant
  fields:
    mission:
      name: mission
      description: 'Le contexte (ex: cafe, volets, batterie)'
      required: true
      selector:
        text: {}
    details:
      name: 'd√©tails'
      description: 'Donn√©es brutes (ex: 15%, nom de la porte)'
      required: false
      selector:
        text: {}
    consigne:
      name: 'consigne sp√©cifique'
      description: 'Nuance pour l''IA (ex: sois plus insistant)'
      required: false
      selector:
        text: {}

  sequence:
    # √âTAPE 1 : Appel au service IA
    - action: ai_task.generate_data
      continue_on_error: true # On continue m√™me si l'IA plante
      data:
        task_name: 'K-2SO Persona - {{ mission }}'
        instructions: >
          # TON ET PERSONNALIT√â
          Tu es K-2SO de Star Wars. Ton ton est factuel, direct et sarcastique.
          Pas d'√©moji, phrases courtes pour le TTS.

          # CONTEXTE DE LA MISSION
          L'action : {{ mission }} 
          {% if details is defined and details != '' %} INFOS : {{ details }} {% endif %}
          {% if consigne is defined and consigne != '' %} NOTE : {{ consigne }} {% endif %}

          G√©n√®re la phrase adapt√©e.
      response_variable: raw_ai_response

    # √âTAPE 2 : Pr√©paration de la r√©ponse (IA ou Secours)
    - variables:
        # Messages de secours si l'IA est hors-ligne
        fallback_msg: >
          {% set msgs = {
            'cafe_pret': "Le caf√© est pr√™t. Je suppose que vous en avez besoin.",
            'batterie_faible': "Niveau de batterie faible (" ~ details ~ ").",
            'porte_frigo_ouverte': "Alerte : porte de r√©frig√©rateur ouverte."
          } %} {{ msgs.get(mission, "Notification : " ~ mission) }}
        
        # Choix final de la variable
        generated_message:
          data: >
            {% if raw_ai_response is defined and raw_ai_response.data is defined and raw_ai_response.data | length > 0 %}
              {{ raw_ai_response.data }}
            {% else %}
              {{ fallback_msg }}
            {% endif %}

    # √âTAPE 3 : On renvoie le message √† l'automatisation qui l'a appel√©
    - stop: Message g√©n√©r√©
      response_variable: generated_message
```

## 3. Comment utiliser ce script dans son auto ?
C'est tr√®s simple, on appelle le script et on r√©cup√®re la r√©ponse dans une variable.

```yaml
- action: script.k_2so_generateur_de_message
  data:
    mission: "machine √† laver"
    consigne: "Dis-lui que √ßa va sentir le poney mort s'il attend trop."
  response_variable: generated_message

- action: notify.alexa_media
  data:
    message: "{{ generated_message.data }}"
    target: media_player.salon
```

---
**Astuce HACF** : N'h√©site pas √† dire que √ßa marche avec OpenAI, Google Gemini ou m√™me Ollama en local !
